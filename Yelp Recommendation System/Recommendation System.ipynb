{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Recommendation system for YELP users using Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.linalg as la\n",
    "import matplotlib\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "matplotlib.use(\"svg\")\n",
    "if not os.environ.get(\"DISABLE_TESTING\", False):\n",
    "    %matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The data obtained with the help of Yelp API and web scraping for the restaurants in Shadyside, Pittsburgh was used to build a recommendation system.\n",
    "\n",
    "For this project, we will only be looking at the ratings data, and ignoring the restaurant data and user reviews for restaurants which could be used to improve the ability of the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file=\"complete_data_shadyside.csv\"):\n",
    "    \"\"\"read the CSV file and process the data.\n",
    "\n",
    "    kwargs:\n",
    "        file : path to the data file\n",
    "    \n",
    "    returns: Tuple[ratings, restaurants, users] where\n",
    "      ratings : Tuple[np.ndarray[int], np.ndarray[int], np.ndarray[float]] -- a list of user ids, restaurant ids, and corresponding ratings\n",
    "      restaurants : Dict[int, str] -- the lookup table from restaurant ID to restaurant name\n",
    "      users : Dict[str, int] -- the lookup table from user name to user ID\n",
    "    \"\"\"\n",
    "    restaurants = {}\n",
    "    users = {}\n",
    "    \n",
    "    data = pd.read_csv(file)\n",
    "    \n",
    "    restaurant_list = list(data[\"restaurant\"].unique())\n",
    "    data[\"restaurant_id\"] = [restaurant_list.index(data[\"restaurant\"][i]) for i in range(data[\"restaurant\"].shape[0])]\n",
    "    \n",
    "    for i in range(len(restaurant_list)):\n",
    "        restaurants[i] = restaurant_list[i]\n",
    "    \n",
    "    user_list = list(data[\"author\"].unique())\n",
    "    data[\"user_id\"] = [user_list.index(data[\"author\"][i]) for i in range(data[\"author\"].shape[0])]\n",
    "    \n",
    "    for i in range(len(user_list)):\n",
    "        users[user_list[i]] = i \n",
    "        \n",
    "    order = [6,0,5,4,1,2,3] # setting column's order\n",
    "    data = data[[data.columns[i] for i in order]]\n",
    "    \n",
    "    #print(data.head())\n",
    "    \n",
    "    return (np.array(data[\"user_id\"]), np.array(data[\"restaurant_id\"]), np.array(data[\"rating\"],np.float32)), restaurants, users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Matrix factorization requires that we have our ratings stored in a matrix of users, so the first task is to take the dataframe and convert it into this format. Typically these matrices are extremely large and sparse, and so we work with sparse matrices here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(ratings_userid, ratings_restaurantid, ratings_rating, test_size=0.1, random_state=0xCAFE):\n",
    "    \"\"\" Given rating data, split the data into training and testing sets and convert them to sparse matrices.\n",
    "\n",
    "        args: \n",
    "            ratings_userid  : np.ndarray[num_ratings] -- vector of user Ids\n",
    "            ratings_restaurantid : np.ndarray[num_ratings] -- vector of restaurant Ids\n",
    "            ratings_rating  : np.ndarray[num_ratings] -- vector of rating values\n",
    "\n",
    "        kwargs:\n",
    "            test_size : float -- fraction of dataset to place in the test set\n",
    "            random_state : int -- the random seed for dataset splitting\n",
    "\n",
    "        return: Tuple[X_train, X_test, movies] \n",
    "            X_train : sp.coo_matrix -- the training data, as a sparse matrix\n",
    "            X_test : sp.coo_matrix -- the test data, as a sparse matrix \n",
    "    \"\"\"\n",
    "    data = np.stack((ratings_userid, ratings_restaurantid, ratings_rating)).T\n",
    "\n",
    "    data_train,data_test = train_test_split(data,test_size=test_size,random_state = random_state) \n",
    "    \n",
    "    X_train = sp.coo_matrix((data_train[:,2],(data_train[:,0],data_train[:,1])),shape=(len(set(ratings_userid)),len(set(ratings_restaurantid))))\n",
    "    X_test = sp.coo_matrix((data_test[:,2],(data_test[:,0],data_test[:,1])),shape=(len(set(ratings_userid)),len(set(ratings_restaurantid))))\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = process(data[0][0], data[0][1], data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<16512x826 sparse matrix of type '<class 'numpy.float64'>'\\n\\twith 67061 stored elements in COOrdinate format>\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<16512x826 sparse matrix of type '<class 'numpy.float64'>'\\n\\twith 7452 stored elements in COOrdinate format>\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Minimization for Collaborative Filtering\n",
    "Now we build the collaborative filtering recommendation system. We will use a method known as alternating least squares. We alternate between optimizing $U$ and $V$ and holding the other constant. By treating one matrix as a constant, we get a weighted least squares problem which we can solve easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X, U, V):\n",
    "    \"\"\" Compute the mean error of the observed ratings in X and their estimated values. \n",
    "\n",
    "        args: \n",
    "            X : np.array[num_users, num_restaurants] -- the ratings matrix\n",
    "            U : np.array[num_users, num_features] -- a matrix of features for each user\n",
    "            V : np.array[num_restaurants,num_features] -- a matrix of features for each restaurant\n",
    "\n",
    "        return: float -- the mean squared error between non-zero entries of X and the ratings\n",
    "            predicted by U and V; as this is an error and not a loss function, you do not need to include the\n",
    "            regularizing terms.\n",
    "        \"\"\"\n",
    "        \n",
    "    X_ = np.dot(U,V.T)\n",
    "    error = ((X_[X!=0] - X[X!=0])**2).sum()/((X!=0).sum())\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_test, k, niters=20, lam=5., verbose=True):\n",
    "    \"\"\" Train a collaborative filtering model. \n",
    "        Args: \n",
    "            X_train : np.array[num_users, num_restaurants] -- the training ratings matrix, assumed dense\n",
    "            X_test : np.array[num_users, num_restaurants] -- the test ratings matrix, assumed dense\n",
    "            k : int -- the number of features in the CF model\n",
    "            niters : int -- number of iterations to run\n",
    "            lam : float -- regularization parameter, shown as lambda\n",
    "            verbose : boolean -- if true, print the error on train and test sets every few iterations \n",
    "\n",
    "        return : Tuple[U, V]\n",
    "            U : np.array[num_users,  num_features] -- the user-feature matrix\n",
    "            V : np.array[num_restaurants, num_features] -- the restaurant-feature matrix\n",
    "    \"\"\"\n",
    "    U = np.random.normal(scale=0.1,size=(X_train.shape[0],k))\n",
    "    V = np.random.normal(scale=0.1,size=(X_train.shape[1],k))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"| Time    | Iter  | Train Err | Test Err |\")\n",
    "        print(\"| ------- | ----- | --------- | -------- |\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for i in range(niters):\n",
    "        for j in range(U.shape[0]):\n",
    "            v = V[X_train[j]!=0]\n",
    "            if(v.shape[0] !=0):\n",
    "                U[j] = la.solve(v.T@v + lam * np.eye(k),v.T@X_train[j][X_train[j]!=0])\n",
    "\n",
    "        for j in range(V.shape[0]):\n",
    "            u = U[X_train[:,j]!=0]\n",
    "            if(u.shape[0] !=0):\n",
    "                V[j] = la.solve(u.T@u+ lam * np.eye(k),u.T@(X_train[X_train[:,j]!=0][:,j]))\n",
    "        \n",
    "        if verbose: \n",
    "            print(f\"| {time.perf_counter() - start_time: 7.3f} |{i+1: 6d} |{error(X_train, U, V):10.4f} |{error(X_test, U, V):9.4f} |\")\n",
    "    \n",
    "    if verbose: \n",
    "        print(\"\")\n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Time    | Iter  | Train Err | Test Err |\n",
      "| ------- | ----- | --------- | -------- |\n",
      "|   1.174 |     1 |   14.0255 |  17.6904 |\n",
      "|   2.613 |     2 |    2.2391 |   6.5662 |\n",
      "|   4.022 |     3 |    1.1114 |   4.0377 |\n",
      "|   5.433 |     4 |    1.0412 |   3.8771 |\n",
      "|   6.839 |     5 |    1.0185 |   3.8662 |\n",
      "|   8.257 |     6 |    1.0064 |   3.8722 |\n",
      "|   9.681 |     7 |    0.9986 |   3.8776 |\n",
      "|  11.089 |     8 |    0.9930 |   3.8801 |\n",
      "|  12.526 |     9 |    0.9887 |   3.8809 |\n",
      "|  14.033 |    10 |    0.9854 |   3.8807 |\n",
      "|  15.470 |    11 |    0.9826 |   3.8802 |\n",
      "|  16.961 |    12 |    0.9803 |   3.8795 |\n",
      "|  18.368 |    13 |    0.9783 |   3.8786 |\n",
      "|  19.770 |    14 |    0.9764 |   3.8773 |\n",
      "|  21.177 |    15 |    0.9747 |   3.8760 |\n",
      "|  22.584 |    16 |    0.9730 |   3.8749 |\n",
      "|  23.983 |    17 |    0.9715 |   3.8741 |\n",
      "|  25.399 |    18 |    0.9702 |   3.8736 |\n",
      "|  26.823 |    19 |    0.9691 |   3.8734 |\n",
      "|  28.253 |    20 |    0.9682 |   3.8735 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u,v = train(data_train.toarray(), data_test.toarray(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "\n",
    "Finally, we need to be able to make recommendations given a matrix factorization. We can do this with the help of estimated ratings matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_restaurant(X, U, V):\n",
    "    \"\"\"Recommend a new restaurant for every user.\n",
    "\n",
    "        args: \n",
    "            X : np.array[num_users, num_restaurants] -- the ratings matrix\n",
    "            U : np.array[num_users, num_features] -- a matrix of features for each user\n",
    "            V : np.array[num_restaurants,num_features] -- a matrix of features for each restaurant\n",
    "\n",
    "        return: List[int] -- a list of restaurant Ids for each user\n",
    "    \"\"\"\n",
    "    \n",
    "    X_ = np.dot(U,V.T)\n",
    "    recommendations = []\n",
    "    \n",
    "    for i in range(X_.shape[0]):\n",
    "        X_[i][X[i]!=0] = 0\n",
    "        recommendations.append(X_[i].argmax())\n",
    "        \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Recommended Restaurants:\n",
      "\n",
      "[('Church Brew Works', 3672), (\"DiAnoia's Eatery\", 3003), ('Point Brugge Caf√©', 1770), ('Hofbrauhaus Pittsburgh', 1546), ('Carmi Soul Food', 1240)]\n"
     ]
    }
   ],
   "source": [
    "recommendation = recommend(data_train.toarray() + data_test.toarray(), u, v)\n",
    "counts = Counter(recommendation)\n",
    "print(\"Most Recommended Restaurants:\\n\")\n",
    "print([(data[1][i], c) for i, c in counts.most_common(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_user(X, U, V, users, restaurants, user_name, n):\n",
    "    \"\"\"Recommend 'n' restaurants for a given user.\n",
    "\n",
    "        args: \n",
    "            X : np.array[num_users, num_restaurants] -- the ratings matrix\n",
    "            U : np.array[num_users, num_features] -- a matrix of features for each user\n",
    "            V : np.array[num_restaurants,num_features] -- a matrix of features for each restaurant\n",
    "            users : Dict[str, int] -- the lookup table from user name to user ID\n",
    "            restaurants : Dict[int, str] -- the lookup table from restaurant ID to restaurant name\n",
    "            user_name : str -- user name for whom recommendations are required\n",
    "            n : int -- number of recommendations\n",
    "            \n",
    "        return: List[int] -- a list of restaurant Ids for the given user\n",
    "    \"\"\"\n",
    "    \n",
    "    X_ = np.dot(U,V.T)\n",
    "    \n",
    "    X_[users[user_name]][X[users[user_name]]!=0] = 0\n",
    "    recommendations = X_[users[user_name]].argsort()[-n:][::-1]\n",
    "    \n",
    "    print(\"Recommendations for user \",user_name,\":\\n\")\n",
    "    print([restaurants[i] for i in recommendations])\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user  Jeremy L. :\n",
      "\n",
      "[\"Carmella's Plates & Pints\", 'Double Wide Grill', 'The Porch at Schenley', 'Girasole Restaurant', 'Caffe Mona La Bistro']\n"
     ]
    }
   ],
   "source": [
    "recommendations = recommend_user(data_train.toarray() + data_test.toarray(), u, v, data[2],data[1], \"Jeremy L.\", 5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
